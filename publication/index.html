<!DOCTYPE html>
<html lang='en' class=''>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name=viewport content="width=device-width, initial-scale=1">



<meta name="description" content="Fan Lyu" />



<title>
	Fan Lyu
	 - Publications 
</title>

<link href="https://fanlyu.com/publication/index.xml" rel="alternate" type="application/rss+xml" title="Fan Lyu" />



<link rel="icon" href="/favicon.png">

	

  
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-MEASUREMENT_ID"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-MEASUREMENT_ID');
        }
      </script>
    
  

















<script src="https://fanlyu.com/js/pico.min.f68158e607f7493b08ceb09d0d24efe0.js" intergrity="md5-9oFY5gf3STsIzrCdDSTv4A==" crossorigin="anonymous"></script>


	





<link rel="stylesheet" href="https://fanlyu.com/css/main.min.790a3134ff5d0656ccfc6c457ca611db.css" crossorigin="anonymous" media="screen"
	integrity="md5-eQoxNP9dBlbM/GxFfKYR2w==">












<link rel="stylesheet" href="https://fanlyu.com/style/style.min.d41d8cd98f00b204e9800998ecf8427e.css" crossorigin="anonymous" media="screen"
	integrity="md5-1B2M2Y8AsgTpgAmY7PhCfg==">










<link rel="stylesheet" href="https://fanlyu.com/css/main.min.1b6695ede8a03de873124c10b957342b.css" crossorigin="anonymous" media="screen"
	integrity="md5-G2aV7eigPehzEkwQuVc0Kw==">


	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>
</head>

<body class="min-h-screen bg-secondary-light dark:bg-secondary text-primary relative pb-24">
	
	<div id="top" class="dark"></div>

<header class="w-full flex items-center justify-between px-5 mx-auto md:pt-8 md:max-w-5xl pt-5">
	
	<div class="flex items-center">
		<a href="https://fanlyu.com/" class="inline-block mx-1 font-bold no-underline select-none">
			<h1 class="hidden md:block font-charter tracking-normal m-0">
				Fan Lyu
			</h1>

			<div class="md:hidden">
				<div class="w-8 h-8 relative font-bold bg-white blend-diff">
	<h1 class="absolute-center m-0 font-charter text-2xl text-gray-100 blend-diff select-none">
		
		Âêï
	</h1>
</div>

			</div>
		</a>
		
	</div>

	<nav class="">
		
		<a href="/"
			class='mx-1 md:mx-2 hover:text-primary-light dark:hover:text-primary-dark no-underline'>
			 Home
		</a>
		
		<a href="/publication"
			class='mx-1 md:mx-2 hover:text-primary-light dark:hover:text-primary-dark no-underline'>
			 Publication
		</a>
		
	</nav>
</header>

	

	<main class="w-full px-4 pt-8 mx-auto md:max-w-4xl overflow-x-hidden md:overflow-visible ">
<h1 class="text-center mx-auto max-w-4xl text-4xl sm:text-5xl md:text-6xl">
    Publications
</h1>



    <h2 class="text-center mx-auto max-w-4xl text-3xl sm:text-4xl md:text-5xl">2025</h2>
    <div class="mx-auto my-16 px-4 max-w-6xl">
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2025_icme_ccotta.png" 
                         alt="Controllable Continual Test-Time Adaptation" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Controllable Continual Test-Time Adaptation</p>
                    <p class="text-gray-600 mt-0">In Proceedings of the IEEE International Conference on Multimedia &amp; Expo, 2025</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Ziqi Shi*, <u><b>Fan Lyu</b></u>* (Project Lead), Ye Liu, Fanhua Shang, Fuyuan Hu, Wei Feng, Zhang Zhang, Liang Wang
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://arxiv.org/pdf/2405.14602" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/RenshengJi/C-CoTTA" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2025_arxiv_ttd.png" 
                         alt="Test-Time Discovery via Hashing Memory" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Test-Time Discovery via Hashing Memory</p>
                    <p class="text-gray-600 mt-0">Preprint on Arxiv</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        <u><b>Fan Lyu</b></u>, Tianle Liu, Zhang Zhang, Fuyuan Hu, Liang Wang
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://arxiv.org/abs/2503.10699" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/fanlyu/ttd" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2025_arxiv_cui.png" 
                         alt="Conformal Uncertainty Indicator for Continual Test-Time Adaptation" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Conformal Uncertainty Indicator for Continual Test-Time Adaptation</p>
                    <p class="text-gray-600 mt-0">Preprint on Arxiv</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        <u><b>Fan Lyu</b></u>, Hanyu Zhao, Ziqi Shi, Ye Liu, Fuyuan Hu, Zhang Zhang, Liang Wang
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://arxiv.org/pdf/2502.02998" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2025-CVPR-TCA.jpg" 
                         alt="Maintaining Consistent Inter-Class Topology in Continual Test-Time Adaptation" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Maintaining Consistent Inter-Class Topology in Continual Test-Time Adaptation</p>
                    <p class="text-gray-600 mt-0">In Proceedings of the IEEE/CVF Computer Vision and Pattern Recognition (CVPR), 2025</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Chenggong Ni*, <u><b>Fan Lyu</b></u>* (Project Lead), Jiayao Tan, Fuyuan Hu, Rui Yao, Tao Zhou
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://example.com/paper" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/example/code" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2025_cvpr_eir.jpg" 
                         alt="Beyond Background Shift: Rethinking Instance Replay in Continual Semantic Segmentation" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Beyond Background Shift: Rethinking Instance Replay in Continual Semantic Segmentation</p>
                    <p class="text-gray-600 mt-0">In Proceedings of the IEEE/CVF Computer Vision and Pattern Recognition (CVPR), 2025</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Hongmei Yin, Tingliang Feng, <u><b>Fan Lyu</b></u> (Project Lead), Fanhua Shang, Hongying Liu, Wei Feng, Liang Wan
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://example.com/paper" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/example/code" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2025_cvpr_open.png" 
                         alt="Dual Semantic Guidance for Open Vocabulary Semantic Segmentation" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Dual Semantic Guidance for Open Vocabulary Semantic Segmentation</p>
                    <p class="text-gray-600 mt-0">In Proceedings of the IEEE/CVF Computer Vision and Pattern Recognition (CVPR), 2025</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Zhengyang Wang, Tingliang Feng, <u><b>Fan Lyu</b></u>, Fanhua Shang, Wei Feng, Liang Wan
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://example.com/paper" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/example/code" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2025_jig_clsurvey.jpg" 
                         alt="A Comprehensive Survey of Continual Learning ÊåÅÁª≠Â≠¶‰π†Á†îÁ©∂ËøõÂ±ï" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">A Comprehensive Survey of Continual Learning ÊåÅÁª≠Â≠¶‰π†Á†îÁ©∂ËøõÂ±ï</p>
                    <p class="text-gray-600 mt-0">Journal of Image and Graphics</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        <u><b>Fan Lyu</b></u>, Liang Wang, Xi Li, Weishi Zheng, Zhang Zhang,Tao Zhou, Fuyuan Hu
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://www.cjig.cn/zh/article/doi/10.11834/jig.240661/" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2025_aaai_rebll.png" 
                         alt="Rebalancing Multi-Label Class-Incremental Learning" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Rebalancing Multi-Label Class-Incremental Learning</p>
                    <p class="text-gray-600 mt-0">In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2025</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Kaile Du, Yifan Zhou, <u><b>Fan Lyu</b></u>, Yuyang Li, Junzhou Xie, Yixi Shen, Fuyuan Hu, Guangcan Liu
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://arxiv.org/pdf/2408.12161" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
    </div>
<hr class="mb-12 my-24 border-secondary-dark dark:border-secondary-light">

    <h2 class="text-center mx-auto max-w-4xl text-3xl sm:text-4xl md:text-5xl">2024</h2>
    <div class="mx-auto my-16 px-4 max-w-6xl">
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_accv_psctta.png" 
                         alt="Parameter-Selective Continual Test-Time Adaptation" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Parameter-Selective Continual Test-Time Adaptation</p>
                    <p class="text-gray-600 mt-0">In Proceedings of the Asian Conference on Computer Vision (ACCV), 2024</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Jiaxu Tian, <u><b>Fan Lyu</b></u>‚Ä† (Corresponding Author)
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://openaccess.thecvf.com/content/ACCV2024/papers/Tian_Parameter-Selective_Continual_Test-Time_Adaptation_ACCV_2024_paper.pdf" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/JiaxuTian/PSMT" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_smc_risk.png" 
                         alt="Understanding Driving Risks via Prompt Learning" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Understanding Driving Risks via Prompt Learning</p>
                    <p class="text-gray-600 mt-0">In the IEEE International Conference on Systems, Man, and Cybernetics (SMC), 2024</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Yubo Chang, <u><b>Fan Lyu</b></u> (Project Lead), Zhang Zhang, Liang Wang
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://ieeexplore.ieee.org/abstract/document/10831354/" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_eccv_csc.png" 
                         alt="Confidence Self-Calibration for Multi-Label Class-Incremental Learning" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Confidence Self-Calibration for Multi-Label Class-Incremental Learning</p>
                    <p class="text-gray-600 mt-0">In European Conference on Computer Vision (ECCV), 2024</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Kaile Du, Yifan Zhou, <u><b>Fan Lyu</b></u>, Yuyang Li, Chen Lu, Guangcan Liu
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://arxiv.org/pdf/2403.12559" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_tcsvt_omb.png" 
                         alt="Overcoming Modality Bias in Question-Driven Sign Language Video Translation" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Overcoming Modality Bias in Question-Driven Sign Language Video Translation</p>
                    <p class="text-gray-600 mt-0">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2024</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Liqing Gao, <u><b>Fan Lyu</b></u>, Peng Shi, Lei Zhu, Junfu Pu, Liang Wan, Wei Feng
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://ieeexplore.ieee.org/abstract/document/10572012" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/glq-1992/QSL" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_cc_final.png" 
                         alt="Towards Long-Term Remembering in Federated Continual Learning" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Towards Long-Term Remembering in Federated Continual Learning</p>
                    <p class="text-gray-600 mt-0">Cognitive Computation, 2024</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Ziqin Zhao, <u><b>Fan Lyu</b></u>* (Project Lead), Linyan Li, Fuyuan Hu, Minming Gu, Li Sun
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://link.springer.com/article/10.1007/s12559-024-10314-z" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_ijcnn_metamask.png" 
                         alt="MetaMask: Improving Few-Shot Semantic Segmentation via Multi-Mask Calibration" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">MetaMask: Improving Few-Shot Semantic Segmentation via Multi-Mask Calibration</p>
                    <p class="text-gray-600 mt-0">In Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN), 2024</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Li Dinghang, Zongqing Lu, Weiliang Zheng, Qingmin Liao, <u><b>Fan Lyu</b></u>
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://ieeexplore.ieee.org/abstract/document/10651371/" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_tiv_ar2vp.png" 
                         alt="Dynamic V2X Perception From Road-to-Vehicle Vision" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Dynamic V2X Perception From Road-to-Vehicle Vision</p>
                    <p class="text-gray-600 mt-0">IEEE Transactions on Intelligent Vehicles (TIV), 2024.</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Jiayao Tan*, <u><b>Fan Lyu</b></u>* (Project Lead), Linyan Li, Fuyuan Hu, Tingliang Feng, Fenglei Xu, Zhang Zhang, Rui Yao, Liang Wang
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://ieeexplore.ieee.org/abstract/document/10552085" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/tjy1423317192/AR2VP" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_cviu_eint.png" 
                         alt="Combinational sign language recognition" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Combinational sign language recognition</p>
                    <p class="text-gray-600 mt-0">Computer Vision and Image Understanding (CVIU), 2024</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Liqing Gao, Wei Feng, <u><b>Fan Lyu</b></u>, Liang Wan
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S1077314224000535" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_aaai_mtlt.png" 
                         alt="Long-Tailed Learning as Multi-Objective Optimization" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Long-Tailed Learning as Multi-Objective Optimization</p>
                    <p class="text-gray-600 mt-0">In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2024</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Weiqi Li, <u><b>Fan Lyu</b></u> (Project Lead), Fanhua Shang, Liang Wan, Wei Feng
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://ojs.aaai.org/index.php/AAAI/article/download/28103/28211" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/WickyLee1998/GBG_v1" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
    </div>
<hr class="mb-12 my-24 border-secondary-dark dark:border-secondary-light">

    <h2 class="text-center mx-auto max-w-4xl text-3xl sm:text-4xl md:text-5xl">2023</h2>
    <div class="mx-auto my-16 px-4 max-w-6xl">
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_iccv_maxdo.png" 
                         alt="Measuring Asymmetric Gradient Discrepancy in Parallel Continual Learning" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Measuring Asymmetric Gradient Discrepancy in Parallel Continual Learning</p>
                    <p class="text-gray-600 mt-0">In Proceedings of International Conference on Computer Vision (ICCV), 2023</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        <u><b>Fan Lyu</b></u>, Qing Sun, Fanhua Shang, Liang Wan, Wei Feng
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.pdf" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/fanlyu/maxdo" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2023_pr_fsl.png" 
                         alt="Multi-semantic hypergraph neural network for effective few-shot learning" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Multi-semantic hypergraph neural network for effective few-shot learning</p>
                    <p class="text-gray-600 mt-0">Pattern Recognition (PR), 2023</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                         Hao Chen, Linyan Li, Fuyuan Hu, <u><b>Fan Lyu</b></u> (Project Lead), Liuqing Zhao, Kaizhu Huang, Wei Feng, Zhenping Xia
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320323003783" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_tmm_agcn&#43;&#43;.png" 
                         alt="Multi-label Continual Learning using Augmented Graph Convolutional Network" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Multi-label Continual Learning using Augmented Graph Convolutional Network</p>
                    <p class="text-gray-600 mt-0">IEEE Transactions on Multimedia, 2023</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Kaile Du*, <u><b>Fan Lyu</b></u>* (Project Lead), Linyan Li, Fuyuan Hu, Wei Feng, Fenglei Xu, Xuefeng Xi
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://arxiv.org/pdf/2211.14763" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/Kaile-Du/AGCN" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2023_tvc_slr.png" 
                         alt="Difference-Guided Multi-Scale Spatial-Temporal Representation for Sign Language Recognition" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Difference-Guided Multi-Scale Spatial-Temporal Representation for Sign Language Recognition</p>
                    <p class="text-gray-600 mt-0">The Visual Computer (TVC), 2023</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                         Liqing Gao, Lianyu Hu, <u><b>Fan Lyu</b></u>, Lei Zhu, Liang Wan, Chi-Man Pun, Wei Feng
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://link.springer.com/article/10.1007/s00371-023-02979-8" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                    </p>
                </div>
            </div>
        
            <div class="flex mb-8">
                
                <div class="w-1/5 relative overflow-hidden">
                    <img src="/img/publications/2024_icme_ocl.png" 
                         alt="Centroid-based Rehearsal for Online Continual Learning" 
                         style="position: absolute; top: 5%; min-width: 100%; height: 90%; object-fit: cover; border: 2px solid #767373; border-radius: 3px;">
                </div>
                
                <div class="w-4/5 pl-8">
                    <p class="text-lg font-bold mt-0">Centroid-based Rehearsal for Online Continual Learning</p>
                    <p class="text-gray-600 mt-0">In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2023</p>
                    <p class="text-gray-600 mt-0">
                        
                        
                        
                        Daofeng Liu*, <u><b>Fan Lyu</b></u>* (Project Lead), Linyan Li, Fuyuan Hu
                    </p>
                    <p class="mt-0">
                        
                            <a href="https://arxiv.org/pdf/2303.02954" class="text-blue-600 hover:underline">Paper Link</a>
                        
                        
                             | 
                            <a href="https://github.com/Daofeng-liu/CDD-R" class="text-blue-600 hover:underline">Code Link</a>
                        
                    </p>
                </div>
            </div>
        
    </div>
<hr class="mb-12 my-24 border-secondary-dark dark:border-secondary-light">


	</main>

	<div class="absolute bottom-0 w-full"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div style="text-align: center;margin-bottom: 10px;">
<span id="busuanzi_container_site_pv">
	<b>Site visit:  </b>
<span id="busuanzi_value_site_pv">

</div>
<footer class="w-full h-24 text-center text-xs text-gray-400 bg-black relative"> 
	<div class="w-full px-6 md:pt-0 md:mx-auto md:max-w-5xl flex flex-1 space-between items-center absolute-center">
		<a href="https://fanlyu.com/" class="absolute">
			<div class="w-8 h-8 relative font-bold bg-white blend-diff">
	<h1 class="absolute-center m-0 font-charter text-2xl text-gray-100 blend-diff select-none">
		
		Âêï
	</h1>
</div>

		</a>

		<div class="h-full flex-1">
			<span class="select-none">
				¬© Powered by <a href="https://gohugo.io/" class="text-gray-400 hover:text-gray-200 no-underline">Hugo</a> & <a href="https://github.com/negrel/hugo-theme-pico" class="text-gray-400 hover:text-gray-200 no-underline">Pico</a>
				¬∑
				Modified by Fan Lyu
			</span>
		</div>
	</div>
</footer>

	</div>
</body>

</html>